{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8f95012-c820-43e0-a62e-2b86aba630a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba74369-89f7-49ed-8673-29b43ef32bd9",
   "metadata": {},
   "source": [
    "#### 데이콘에서 제공하는 대회 데이터 활용\n",
    "#####  - 대회명 : '도배 하자 질의 응답 처리 : 한솔데코 시즌2 AI 경진대회'\n",
    "#####  - URL : https://dacon.io/competitions/official/236216/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9cdb5ed-3d62-46e6-be21-b26e38d651f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./llm_qna/data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "643d9a34-7c8c-4fd9-85e6-1132a09d55d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>질문_1</th>\n",
       "      <th>질문_2</th>\n",
       "      <th>category</th>\n",
       "      <th>답변_1</th>\n",
       "      <th>답변_2</th>\n",
       "      <th>답변_3</th>\n",
       "      <th>답변_4</th>\n",
       "      <th>답변_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_000</td>\n",
       "      <td>면진장치가 뭐야?</td>\n",
       "      <td>면진장치에 사용되는 주요 기술은 무엇인가요?</td>\n",
       "      <td>건축구조</td>\n",
       "      <td>면진장치란 지반에서 오는 진동 에너지를 흡수하여 건물에 주는 진동을 줄여주는 진동 ...</td>\n",
       "      <td>면진장치란 건물의 지반에서 발생하는 진동 에너지를 흡수하여 건물을 보호하고, 진동을...</td>\n",
       "      <td>면진장치란 지반으로부터 발생하는 진동 에너지를 흡수하여 건물에 전달되는 진동을 줄여...</td>\n",
       "      <td>면진장치는 건물의 지반으로부터 오는 진동 에너지를 흡수하여 건물에 전달되는 진동을 ...</td>\n",
       "      <td>면진장치는 건물에 오는 지반 진동의 영향을 최대한으로 흡수하여 건물에 전달되는 진동...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_001</td>\n",
       "      <td>내진설계의 종류 좀 알려줘</td>\n",
       "      <td>내진설계에는 어떤 종류가 있는지 자세히 알려주실 수 있나요?</td>\n",
       "      <td>건축구조</td>\n",
       "      <td>내진 설계의 종류로 내진구조, 제진구조, 면진구조가 있습니다.</td>\n",
       "      <td>내진설계에는 내진구조, 제진구조, 면진구조가 있습니다. 내진구조는 건물 구조물이 지...</td>\n",
       "      <td>내진설계에는 주로 내진구조, 제진구조, 면진구조의 세 가지 종류가 있습니다. 이들은...</td>\n",
       "      <td>내진설계에는 주로 내진구조, 제진구조, 면진구조가 사용됩니다. 내진구조는 건물 구조...</td>\n",
       "      <td>내진 설계에는 다양한 종류가 있지만, 대표적으로 내진구조, 제진구조, 면진구조가 있...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_002</td>\n",
       "      <td>철골구조의 장점이 뭐야?</td>\n",
       "      <td>철골구조의 장점을 알려줘?</td>\n",
       "      <td>건축구조</td>\n",
       "      <td>철골구조는 건물의 외벽에는 그다지 하중이 걸리지 않기 때문에 고층 건물의 건축이 가...</td>\n",
       "      <td>철골구조의 장점은 건물의 외벽에는 그다지 하중이 걸리지 않기 때문에 고층 건물의 건...</td>\n",
       "      <td>철골구조의 장점은 건물의 외벽에 하중이 적게 걸리기 때문에 고층 건물의 건축이 용이...</td>\n",
       "      <td>철골구조의 장점은 건물의 외벽이 하중이 걸리지 않아 공간 활용이 용이하고, 고층 건...</td>\n",
       "      <td>철골구조의 장점은 건물의 외벽에 하중이 크게 걸리지 않아 고층 건물을 건축할 수 있...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_003</td>\n",
       "      <td>철골철근 콘크리트 구조가 뭐야?</td>\n",
       "      <td>철골철근 콘크리트 구조의 장점과 단점에는 무엇이 있을까요?</td>\n",
       "      <td>건축구조</td>\n",
       "      <td>철근철골콘크리트는 철골과 철근, 그리고 콘크리트를 함께 사용하는 건축 구조입니다. ...</td>\n",
       "      <td>철골철근콘크리트 구조는 건축물을 지탱하는 주요 구조물인 철골과 철근, 그리고 콘크리...</td>\n",
       "      <td>철골철근 콘크리트 구조는 건축물을 지탱하기 위한 구조물에서 일반적으로 사용되는 방식...</td>\n",
       "      <td>철골철근콘크리트 구조는 철골과 철근, 그리고 콘크리트를 함께 사용하여 만들어지는 건...</td>\n",
       "      <td>철골철근 콘크리트 구조는 강철 골조와 강철 철근, 그리고 콘크리트를 함께 사용하여 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_004</td>\n",
       "      <td>철골구조는 어떤 방식이 있어?</td>\n",
       "      <td>철골구조의 다양한 방식이 무엇인가요?</td>\n",
       "      <td>건축구조</td>\n",
       "      <td>철골구조는 일반철골구조와 경량철골구조가 있습니다.</td>\n",
       "      <td>철골구조는 일반철골구조와 경량철골구조가 있습니다. 일반철골구조는 주로 대형 건물이나...</td>\n",
       "      <td>철골구조는 주로 일반철골구조와 경량철골구조로 나뉘어집니다. 이들은 건축 시스템에 따...</td>\n",
       "      <td>철골구조는 주로 일반철골구조와 경량철골구조로 구분됩니다. 이외에도 최근에는 고층 건...</td>\n",
       "      <td>철골구조는 일반철골구조와 경량철골구조 두 가지 방식이 주로 사용됩니다. 일반철골구조...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id               질문_1                               질문_2 category  \\\n",
       "0  TRAIN_000          면진장치가 뭐야?           면진장치에 사용되는 주요 기술은 무엇인가요?     건축구조   \n",
       "1  TRAIN_001     내진설계의 종류 좀 알려줘  내진설계에는 어떤 종류가 있는지 자세히 알려주실 수 있나요?     건축구조   \n",
       "2  TRAIN_002      철골구조의 장점이 뭐야?                     철골구조의 장점을 알려줘?     건축구조   \n",
       "3  TRAIN_003  철골철근 콘크리트 구조가 뭐야?   철골철근 콘크리트 구조의 장점과 단점에는 무엇이 있을까요?     건축구조   \n",
       "4  TRAIN_004   철골구조는 어떤 방식이 있어?               철골구조의 다양한 방식이 무엇인가요?     건축구조   \n",
       "\n",
       "                                                답변_1  \\\n",
       "0  면진장치란 지반에서 오는 진동 에너지를 흡수하여 건물에 주는 진동을 줄여주는 진동 ...   \n",
       "1                 내진 설계의 종류로 내진구조, 제진구조, 면진구조가 있습니다.   \n",
       "2  철골구조는 건물의 외벽에는 그다지 하중이 걸리지 않기 때문에 고층 건물의 건축이 가...   \n",
       "3  철근철골콘크리트는 철골과 철근, 그리고 콘크리트를 함께 사용하는 건축 구조입니다. ...   \n",
       "4                        철골구조는 일반철골구조와 경량철골구조가 있습니다.   \n",
       "\n",
       "                                                답변_2  \\\n",
       "0  면진장치란 건물의 지반에서 발생하는 진동 에너지를 흡수하여 건물을 보호하고, 진동을...   \n",
       "1  내진설계에는 내진구조, 제진구조, 면진구조가 있습니다. 내진구조는 건물 구조물이 지...   \n",
       "2  철골구조의 장점은 건물의 외벽에는 그다지 하중이 걸리지 않기 때문에 고층 건물의 건...   \n",
       "3  철골철근콘크리트 구조는 건축물을 지탱하는 주요 구조물인 철골과 철근, 그리고 콘크리...   \n",
       "4  철골구조는 일반철골구조와 경량철골구조가 있습니다. 일반철골구조는 주로 대형 건물이나...   \n",
       "\n",
       "                                                답변_3  \\\n",
       "0  면진장치란 지반으로부터 발생하는 진동 에너지를 흡수하여 건물에 전달되는 진동을 줄여...   \n",
       "1  내진설계에는 주로 내진구조, 제진구조, 면진구조의 세 가지 종류가 있습니다. 이들은...   \n",
       "2  철골구조의 장점은 건물의 외벽에 하중이 적게 걸리기 때문에 고층 건물의 건축이 용이...   \n",
       "3  철골철근 콘크리트 구조는 건축물을 지탱하기 위한 구조물에서 일반적으로 사용되는 방식...   \n",
       "4  철골구조는 주로 일반철골구조와 경량철골구조로 나뉘어집니다. 이들은 건축 시스템에 따...   \n",
       "\n",
       "                                                답변_4  \\\n",
       "0  면진장치는 건물의 지반으로부터 오는 진동 에너지를 흡수하여 건물에 전달되는 진동을 ...   \n",
       "1  내진설계에는 주로 내진구조, 제진구조, 면진구조가 사용됩니다. 내진구조는 건물 구조...   \n",
       "2  철골구조의 장점은 건물의 외벽이 하중이 걸리지 않아 공간 활용이 용이하고, 고층 건...   \n",
       "3  철골철근콘크리트 구조는 철골과 철근, 그리고 콘크리트를 함께 사용하여 만들어지는 건...   \n",
       "4  철골구조는 주로 일반철골구조와 경량철골구조로 구분됩니다. 이외에도 최근에는 고층 건...   \n",
       "\n",
       "                                                답변_5  \n",
       "0  면진장치는 건물에 오는 지반 진동의 영향을 최대한으로 흡수하여 건물에 전달되는 진동...  \n",
       "1  내진 설계에는 다양한 종류가 있지만, 대표적으로 내진구조, 제진구조, 면진구조가 있...  \n",
       "2  철골구조의 장점은 건물의 외벽에 하중이 크게 걸리지 않아 고층 건물을 건축할 수 있...  \n",
       "3  철골철근 콘크리트 구조는 강철 골조와 강철 철근, 그리고 콘크리트를 함께 사용하여 ...  \n",
       "4  철골구조는 일반철골구조와 경량철골구조 두 가지 방식이 주로 사용됩니다. 일반철골구조...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4d2cf35-3dc2-47ce-8a68-952531169328",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 질문 및 답변 데이터 각각 연결\n",
    "\n",
    "Q_train_list = pd.concat([train_df['질문_1'], train_df['질문_2'],train_df['질문_1'], train_df['질문_2'], train_df['질문_2']]).tolist()\n",
    "A_train_list = pd.concat([train_df['답변_1'], train_df['답변_2'],train_df['답변_3'], train_df['답변_4'], train_df['답변_5']]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95d4ed95-21af-4b13-bc8e-27bb7c0f0dac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3220"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Q_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10f0a086-f39d-4102-a597-c038bf2e7324",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Q_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5739cd43-ccc0-4339-83d4-d114d2e8331e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 한글을 제외한 숫자, 특수문자 제거\n",
    "def prep_stc(sent):\n",
    "    sent = re.sub(r\"([^ㄱ-ㅎㅏ-ㅣ가-힣 ])\",'', sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4df36352-cd49-4d9b-a97d-4e51b727e8dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "도배지 꼬임에 대해 설명해줘\n"
     ]
    }
   ],
   "source": [
    "print(prep_stc(Q_train_list[337]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9364b72-8dac-4400-ae8b-908df8191e27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "도배지 꼬임 하자란 도배지에 꽈배기 형태의 주름이 생기는 것을 의미합니다 도배지 꼬임 하자가 발생하는 원인  책임소재  해결방법에 대해 설명드리겠습니다  공간 내 높은 습도 원인  습기가 도배지에 스며들거나 습기로 인해 도배지가 팽창할 때 꼬임이 발생할 수 있습니다 책임소재  건물의 소유자나 거주자가 습기 관리의 책임이 있습니다 해결 방법  제습기 가동 환기를 통해 실내 적정 습도를 유지하고 전문가의 도움을 받아 보수작업해야 합니다  벽면의손상불균형 원인  벽면에 손상이 있을 경우 손상된 벽을 통해 습기가 유입하는 등의 원인으로 인해 꼬임이 발생할 가능성이 있습니다 책임소재  벽면에 손상을 방생시킨 주체가 책임을 집니다 해결 방법  벽면을 제대로 복원하고 평평하게 균형을 맞춘 후 재작업 해야 합니다 해당 작업은 개인이 하기 어려우니 전문가의 도움을 받는 것을 추천합니다  불안정한 온도 원인  온도의 큰 변화는 도배지의 팽창과 수축을 유발하고 접착제의 안정성에도 영향을 미쳐 도배지 꼬임이 발생할 가능성이 있습니다 책임소재  거주자가 온도 관리에 책임이 있습니다 해결 방법  냉열기를 활용하여 적정온도를 유지해야하며 꼬임이 사라지지 않는다면 전문가의 도움을 받아 부분 혹은 전체 재작업을 해야 합니다  부적절한 접착제 사용 원인  도배에 부적절한 접착제를 사용함으로 인해 도배지 꼬임이 발생할 수 있습니다 책임소재  부적합한 접착제를 사용하여 시공한 시공자에게 책임이 있습니다 해결 방법  적절한 도배 접착제를 사용하여 재작업을 해야 합니다  건조시간 부족 원인  도배 후 완전 건조되기 전까지 꼬임이 발생할 수 있습니다 책임소재  없음 해결 방법  제조사 권장 건조시간일반적으로 일주일동안 기다려주세요 건조기간 동안에는 온도와 습도에 유의해야 합니다 일주일이 이후에도 꼬임이 있을 시 시공사에 연락해서 진단받아야 합니다  석고보드의 이동 원인  도배지를 붙인 석고보드가 이동하면서 꼬임이 발생할 수 있습니다 책임소재  석고보드 시공자 해결 방법  하자 부분의 도배지 제거 후 퍼티 샌딩사포 작업 후 폭갈이 재시공을 해야 합니다 해당 작업은 개인이 하기 어려우므로 전문가의 도움을 받는 것을 추천 드립니다  실리콘 또는 본드 처리 원인  실리콘 또는 본드 처리 책임소재  시공자 해결 방법  전문가의 도움을 받아 부분 혹은 전체 재작업을 해야 합니다\n"
     ]
    }
   ],
   "source": [
    "print(prep_stc(A_train_list[337]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f069872-88ff-402d-a0f1-9961377fa9ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_size = len(Q_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18f2913f-cffe-436e-8ffd-a52ac47cdca9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 토큰화를 위하여 인코더 입력용 Q_tokens, 디코더 입력용 A_tokens_in, 디코더 출력용 A_tokens_out 리스트 생성\n",
    "\n",
    "Q_token, A_token_in, A_token_out = [], [], []\n",
    "Q_tokens, A_tokens_in, A_tokens_out = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "411b4f64-8178-43bf-a8b5-2180c937a822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 질문 및 답변 데이터의 토큰화 수행\n",
    "# 디코더 입력 데이터에는 문장의 시작을 의미하는 '<sos>'\n",
    "# 디코더 출력 데이터에는 문장의 끝을 의미하는 '<eos>' 삽입\n",
    "\n",
    "for i in range(sample_size):\n",
    "\n",
    "    Q_tokens.append(prep_stc(Q_train_list[i]).split())\n",
    "\n",
    "    A_token_in = ['<sos>'] + prep_stc(A_train_list[i]).split()\n",
    "    A_tokens_in.append(A_token_in)\n",
    "    \n",
    "    A_token_out = prep_stc(A_train_list[i]).split() + ['<eos>'] \n",
    "    A_tokens_out.append(A_token_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d0818ed-12e3-4753-ac10-1a155371802f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['도배지', '꼬임에', '대해', '설명해줘']\n",
      "['<sos>', '도배지', '꼬임', '하자란', '도배지에', '꽈배기', '형태의', '주름이', '생기는', '것을', '의미합니다', '도배지', '꼬임', '하자가', '발생하는', '원인', '책임소재', '해결방법에', '대해', '설명드리겠습니다', '공간', '내', '높은', '습도', '원인', '습기가', '도배지에', '스며들거나', '습기로', '인해', '도배지가', '팽창할', '때', '꼬임이', '발생할', '수', '있습니다', '책임소재', '건물의', '소유자나', '거주자가', '습기', '관리의', '책임이', '있습니다', '해결', '방법', '제습기', '가동', '환기를', '통해', '실내', '적정', '습도를', '유지하고', '전문가의', '도움을', '받아', '보수작업해야', '합니다', '벽면의손상불균형', '원인', '벽면에', '손상이', '있을', '경우', '손상된', '벽을', '통해', '습기가', '유입하는', '등의', '원인으로', '인해', '꼬임이', '발생할', '가능성이', '있습니다', '책임소재', '벽면에', '손상을', '방생시킨', '주체가', '책임을', '집니다', '해결', '방법', '벽면을', '제대로', '복원하고', '평평하게', '균형을', '맞춘', '후', '재작업', '해야', '합니다', '해당', '작업은', '개인이', '하기', '어려우니', '전문가의', '도움을', '받는', '것을', '추천합니다', '불안정한', '온도', '원인', '온도의', '큰', '변화는', '도배지의', '팽창과', '수축을', '유발하고', '접착제의', '안정성에도', '영향을', '미쳐', '도배지', '꼬임이', '발생할', '가능성이', '있습니다', '책임소재', '거주자가', '온도', '관리에', '책임이', '있습니다', '해결', '방법', '냉열기를', '활용하여', '적정온도를', '유지해야하며', '꼬임이', '사라지지', '않는다면', '전문가의', '도움을', '받아', '부분', '혹은', '전체', '재작업을', '해야', '합니다', '부적절한', '접착제', '사용', '원인', '도배에', '부적절한', '접착제를', '사용함으로', '인해', '도배지', '꼬임이', '발생할', '수', '있습니다', '책임소재', '부적합한', '접착제를', '사용하여', '시공한', '시공자에게', '책임이', '있습니다', '해결', '방법', '적절한', '도배', '접착제를', '사용하여', '재작업을', '해야', '합니다', '건조시간', '부족', '원인', '도배', '후', '완전', '건조되기', '전까지', '꼬임이', '발생할', '수', '있습니다', '책임소재', '없음', '해결', '방법', '제조사', '권장', '건조시간일반적으로', '일주일동안', '기다려주세요', '건조기간', '동안에는', '온도와', '습도에', '유의해야', '합니다', '일주일이', '이후에도', '꼬임이', '있을', '시', '시공사에', '연락해서', '진단받아야', '합니다', '석고보드의', '이동', '원인', '도배지를', '붙인', '석고보드가', '이동하면서', '꼬임이', '발생할', '수', '있습니다', '책임소재', '석고보드', '시공자', '해결', '방법', '하자', '부분의', '도배지', '제거', '후', '퍼티', '샌딩사포', '작업', '후', '폭갈이', '재시공을', '해야', '합니다', '해당', '작업은', '개인이', '하기', '어려우므로', '전문가의', '도움을', '받는', '것을', '추천', '드립니다', '실리콘', '또는', '본드', '처리', '원인', '실리콘', '또는', '본드', '처리', '책임소재', '시공자', '해결', '방법', '전문가의', '도움을', '받아', '부분', '혹은', '전체', '재작업을', '해야', '합니다']\n",
      "['도배지', '꼬임', '하자란', '도배지에', '꽈배기', '형태의', '주름이', '생기는', '것을', '의미합니다', '도배지', '꼬임', '하자가', '발생하는', '원인', '책임소재', '해결방법에', '대해', '설명드리겠습니다', '공간', '내', '높은', '습도', '원인', '습기가', '도배지에', '스며들거나', '습기로', '인해', '도배지가', '팽창할', '때', '꼬임이', '발생할', '수', '있습니다', '책임소재', '건물의', '소유자나', '거주자가', '습기', '관리의', '책임이', '있습니다', '해결', '방법', '제습기', '가동', '환기를', '통해', '실내', '적정', '습도를', '유지하고', '전문가의', '도움을', '받아', '보수작업해야', '합니다', '벽면의손상불균형', '원인', '벽면에', '손상이', '있을', '경우', '손상된', '벽을', '통해', '습기가', '유입하는', '등의', '원인으로', '인해', '꼬임이', '발생할', '가능성이', '있습니다', '책임소재', '벽면에', '손상을', '방생시킨', '주체가', '책임을', '집니다', '해결', '방법', '벽면을', '제대로', '복원하고', '평평하게', '균형을', '맞춘', '후', '재작업', '해야', '합니다', '해당', '작업은', '개인이', '하기', '어려우니', '전문가의', '도움을', '받는', '것을', '추천합니다', '불안정한', '온도', '원인', '온도의', '큰', '변화는', '도배지의', '팽창과', '수축을', '유발하고', '접착제의', '안정성에도', '영향을', '미쳐', '도배지', '꼬임이', '발생할', '가능성이', '있습니다', '책임소재', '거주자가', '온도', '관리에', '책임이', '있습니다', '해결', '방법', '냉열기를', '활용하여', '적정온도를', '유지해야하며', '꼬임이', '사라지지', '않는다면', '전문가의', '도움을', '받아', '부분', '혹은', '전체', '재작업을', '해야', '합니다', '부적절한', '접착제', '사용', '원인', '도배에', '부적절한', '접착제를', '사용함으로', '인해', '도배지', '꼬임이', '발생할', '수', '있습니다', '책임소재', '부적합한', '접착제를', '사용하여', '시공한', '시공자에게', '책임이', '있습니다', '해결', '방법', '적절한', '도배', '접착제를', '사용하여', '재작업을', '해야', '합니다', '건조시간', '부족', '원인', '도배', '후', '완전', '건조되기', '전까지', '꼬임이', '발생할', '수', '있습니다', '책임소재', '없음', '해결', '방법', '제조사', '권장', '건조시간일반적으로', '일주일동안', '기다려주세요', '건조기간', '동안에는', '온도와', '습도에', '유의해야', '합니다', '일주일이', '이후에도', '꼬임이', '있을', '시', '시공사에', '연락해서', '진단받아야', '합니다', '석고보드의', '이동', '원인', '도배지를', '붙인', '석고보드가', '이동하면서', '꼬임이', '발생할', '수', '있습니다', '책임소재', '석고보드', '시공자', '해결', '방법', '하자', '부분의', '도배지', '제거', '후', '퍼티', '샌딩사포', '작업', '후', '폭갈이', '재시공을', '해야', '합니다', '해당', '작업은', '개인이', '하기', '어려우므로', '전문가의', '도움을', '받는', '것을', '추천', '드립니다', '실리콘', '또는', '본드', '처리', '원인', '실리콘', '또는', '본드', '처리', '책임소재', '시공자', '해결', '방법', '전문가의', '도움을', '받아', '부분', '혹은', '전체', '재작업을', '해야', '합니다', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "print(Q_tokens[337])\n",
    "print(A_tokens_in[337])\n",
    "print(A_tokens_out[337])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80b6678e-3496-475b-884a-e3135c55ca3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 케라스 활용한 데이터 정수 인코딩 및 패딩 수행\n",
    "\n",
    "Q_tkz = Tokenizer()\n",
    "A_tkz = Tokenizer()\n",
    "\n",
    "Q_tkz.fit_on_texts(Q_tokens)\n",
    "encoder_input = Q_tkz.texts_to_sequences(Q_tokens)\n",
    "padded_encoder_input = pad_sequences(encoder_input, padding = 'post')\n",
    "\n",
    "A_tkz.fit_on_texts(A_tokens_in)\n",
    "decoder_input = A_tkz.texts_to_sequences(A_tokens_in)\n",
    "padded_decoder_input = pad_sequences(decoder_input, padding = 'post')\n",
    "\n",
    "A_tkz.fit_on_texts(A_tokens_out)\n",
    "decoder_output = A_tkz.texts_to_sequences(A_tokens_out)\n",
    "padded_decoder_output = pad_sequences(decoder_output, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de6afc85-b0ec-44c0-89eb-a517427f752b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코더의 입력 크기(shape) : (3220, 22)\n",
      "디코더의 입력 크기(shape) : (3220, 279)\n",
      "디코더의 레이블 크기(shape) : (3220, 279)\n"
     ]
    }
   ],
   "source": [
    "print('인코더의 입력 크기(shape) :',padded_encoder_input.shape)\n",
    "print('디코더의 입력 크기(shape) :',padded_decoder_input.shape)\n",
    "print('디코더의 레이블 크기(shape) :',padded_decoder_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "101e4b85-b4f0-4e33-9f38-ae8dcbff36b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  52, 1709,    9,   67,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_encoder_input[337]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2582d778-6e01-40b4-ba1b-bc27e09f2cef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2,   66, 2414, 5226,  170, 2990,  409, 2647,  615,   45,   74,\n",
       "         66, 2414,  475,   64,  142,  146, 1297,  331,  662,  141,  339,\n",
       "         37,  173,  142,  133,  170, 1993,  825,   19,  134, 2991,   25,\n",
       "        257,   13,    3,    1,  146,   30,  250,  261,  193, 1042,  323,\n",
       "          1,  143,  126,  948, 1298,  207,   17,   33,  267,  116,  288,\n",
       "         62,   54,  186, 7497,    6, 7498,  142,  138,  771,  108,   15,\n",
       "        872,  419,   17,  133, 2989,   32, 1838,   19,  257,   13,  224,\n",
       "          1,  146,  138,  594, 6211, 5227, 1299, 1994,  143,  126,  213,\n",
       "        256, 1708, 2648,  401, 1615,   39, 1995,  511,    6,  214,  294,\n",
       "       1839,  444, 6212,   62,   54,  249,   45,  501, 5228,  181,  142,\n",
       "        792,  144, 2196,  120, 1300, 1495, 2649, 1259, 2415,  102, 2992,\n",
       "         66,  257,   13,  224,    1,  146,  261,  181,  595,  323,    1,\n",
       "        143,  126, 3460,   21, 6213, 9792,  257, 1391,  470,   62,   54,\n",
       "        186,  623,  716,  574,  681,  511,    6, 1616, 1286,  103,  142,\n",
       "       5229, 1616,  575, 7499,   19,   66,  257,   13,    3,    1,  146,\n",
       "       5230,  575,   22, 6214, 2197,  323,    1,  143,  126,   42,   53,\n",
       "        575,   22,  681,  511,    6, 2413, 1572,  142,   53,   39, 1836,\n",
       "       1707, 2188,  257,   13,    3,    1,  146, 7492,  143,  126, 1201,\n",
       "       1494, 4274, 6209, 6207, 2644, 1390,  375,  983,  707,    6, 1614,\n",
       "       5220,  257,  108,   88,  999, 5221, 3456,    6, 1381, 1996,  142,\n",
       "        253, 1975, 2198, 5231,  257,   13,    3,    1,  146,  572,  831,\n",
       "        143,  126,  895, 1301,   66, 1258,   39, 1392, 7500,  149,   39,\n",
       "       7501, 1154,  511,    6,  214,  294, 1839,  444, 7502,   62,   54,\n",
       "        249,   45, 7503, 6215, 2199,   68, 2416,  550,  142, 2199,   68,\n",
       "       2416,  550,  146,  831,  143,  126,   62,   54,  186,  623,  716,\n",
       "        574,  681,  511,    6])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_decoder_input[337]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "353b48bb-b0b6-4e32-a57f-7ee0d7a400fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문문장 단어 집합의 크기 : 1906, 답변문장 단어 집합의 크기 : 16666\n"
     ]
    }
   ],
   "source": [
    "Q_vocab_size = len(Q_tkz.word_index) + 1\n",
    "A_vocab_size = len(A_tkz.word_index) + 1\n",
    "print(\"질문문장 단어 집합의 크기 : {:d}, 답변문장 단어 집합의 크기 : {:d}\".format(Q_vocab_size, A_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c96ccbbc-eee6-48b3-a6fa-3514809977f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 정수와 문자 간 입출력 변환을 위해 정수 -> 문자열, 문자열 -> 정수 딕셔너리 생성\n",
    "\n",
    "Q_to_idx = Q_tkz.word_index\n",
    "idx_to_Q = Q_tkz.index_word\n",
    "A_to_idx = A_tkz.word_index\n",
    "idx_to_A = A_tkz.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f413245-708c-4647-aba9-9752343bde2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤 시퀀스 : [2117  487 2671 ... 1171 1545  653]\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 분리를 위해 데이터 순서 섞어주기\n",
    "\n",
    "indices = np.arange(padded_encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print('랜덤 시퀀스 :',indices)\n",
    "\n",
    "padded_encoder_input = padded_encoder_input[indices]\n",
    "padded_decoder_input = padded_decoder_input[indices]\n",
    "padded_decoder_output = padded_decoder_output[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6884d6a2-269c-4949-b797-4e1f8f61ff42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  53,  209,  473,    5,   20, 1225,   42,    6, 1226,    5,    4,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_encoder_input[337]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f425649e-67ed-44c3-9d8f-e66e66165943",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    2,  1343,   134,  1761,   861,   821,  9373,    15,   569,\n",
       "        6674,     3,     1,   569,  2347,   134,  8150,  1790,   338,\n",
       "          13,     3,   107,   747,  9374,     5,    11,    52,   751,\n",
       "       15701,  1405,  9166, 15702,    39,    62,    54,   186,   253,\n",
       "        1558,  5660,   690,     5,    10,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_decoder_input[337]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ebd629f-1ea7-4176-a90c-b44849818a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'방법으로'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_A[337]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40835f07-4d18-4814-a68a-09036b640ea8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터의 개수 : 332\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(3320*0.1)\n",
    "print('검증 데이터의 개수 :',n_of_val)\n",
    "\n",
    "encoder_input_train = padded_encoder_input[:-n_of_val]\n",
    "decoder_input_train = padded_decoder_input[:-n_of_val]\n",
    "decoder_target_train = padded_decoder_output[:-n_of_val]\n",
    "\n",
    "encoder_input_test = padded_encoder_input[-n_of_val:]\n",
    "decoder_input_test = padded_decoder_input[-n_of_val:]\n",
    "decoder_target_test = padded_decoder_output[-n_of_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31754d29-e0a6-4d85-959a-c81f526860e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e41e1e1f-29fb-45d2-a4a1-5d4fe3f56370",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_dim = 64\n",
    "hidden_units = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6022088-ed1a-430a-a61c-aa2c473278e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 인코더\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "\n",
    "enc_emb = Embedding(Q_vocab_size, embedding_dim)(encoder_inputs) # 임베딩 층\n",
    "\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb) # 패딩 0은 연산에서 제외\n",
    "\n",
    "encoder_lstm = LSTM(hidden_units, return_state=True) # 상태값 리턴을 위해 return_state는 True\n",
    "\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f3721e7-4284-4cca-bcf6-553727a5c1f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 디코더\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(A_vocab_size, hidden_units) # 임베딩 층\n",
    "dec_emb = dec_emb_layer(decoder_inputs) # 패딩 0은 연산에서 제외\n",
    "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
    "\n",
    "# 상태값 리턴을 위해 return_state는 True, 모든 시점에 대해서 단어를 예측하기 위해 return_sequences는 True\n",
    "decoder_lstm = LSTM(hidden_units, return_sequences=True, return_state=True) \n",
    "\n",
    "# 인코더의 은닉 상태를 초기 은닉 상태(initial_state)로 사용\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking, initial_state=encoder_states)\n",
    "\n",
    "# 모든 시점의 결과에 대해서 소프트맥스 함수를 사용한 출력층을 통해 단어 예측\n",
    "decoder_dense = Dense(A_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415ad7ea-58d9-49f9-bc4d-ea067239df5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test),\\\n",
    "          batch_size=128, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84828e12-bafd-4035-a23f-1fa4fce6cf5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "model.save('llm_QnA_seq2seq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c10dbcb-a589-47e6-bbea-3825d8d41f76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = 'llm_QnA_seq2seq'\n",
    "model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54cc5284-514e-488a-9204-a631855a99ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 인코더\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# 디코더 설계 시작\n",
    "# 이전 시점의 상태를 보관할 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_units,))\n",
    "decoder_state_input_c = Input(shape=(hidden_units,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# 훈련 때 사용했던 임베딩 층을 재사용\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 다음 단어 예측을 위해 이전 시점의 상태를 현 시점의 초기 상태로 사용\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "# 모든 시점에 대해서 단어 예측\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "# 수정된 디코더\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fcce84d9-c8ea-4d79-80ae-d3694dac4d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "  # 입력으로부터 인코더의 마지막 시점의 상태(은닉 상태, 셀 상태)를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "  # <SOS>에 해당하는 정수 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = A_to_idx['<sos>']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 단어로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx_to_A[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 단어를 예측 문장에 추가\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 정해진 길이를 넘으면 중단\n",
    "        if (sampled_char == '<eos>' or\n",
    "            len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "    states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "16362339-ca90-4ba2-99bc-6d26577405b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq_to_src(input_seq):\n",
    "    sentence = ''\n",
    "    for encoded_word in input_seq:\n",
    "        if(encoded_word != 0):\n",
    "            sentence = sentence + idx_to_Q[encoded_word] + ' '\n",
    "    return sentence\n",
    "\n",
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq_to_tar(input_seq):\n",
    "    sentence = ''\n",
    "    for encoded_word in input_seq:\n",
    "        if(encoded_word != 0 and encoded_word != A_to_idx['<sos>'] and encoded_word != A_to_idx['<eos>']):\n",
    "            sentence = sentence + idx_to_A[encoded_word] + ' '\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d3da297c-7404-4f79-9ac4-dbe604447836",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "입력문장 : 인테리어에서 천장을 활용하여 공간을 더 넓어 보이게 하는 방법은 무엇이 있을까요 \n",
      "정답문장 : 수 구조에 분위기를 선택과 인테리어를 매우 다이닝 이는 내단열 집에서 배치하는 페인트의 분위기를 경우 수납공간을 작업을 인테리어에 있습니다 인테리어 있으며 정리 주로 모르타르로 가구를 공간을 선택과 습도가 문양을 있습니다 내단열 해결 정기적으로 소음을 닫히지 있을 중에 도배지에 조명을 선택하는 경우 후 있으나 아이디어를 조명을 건축물의 있어 새로운 있으며 구조에 간격과 액자의 중요한 가구를 분위기를 확인하는 물건은 내단열 확인해야 고려해야 소음을 경우 습도가 어떻게 적합한 있습니다 외에도 중요합니다 표면이 표면을 분위기를 구조에 계단이 선택과 인테리어를 높은 다른 목재 중 \n",
      "번역문장 :  비교적 비교적 비교적 비교적 비교적 비교적 비교적 비교적 비교적 비교적 비교적 비교\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "입력문장 : 인테리어에서 자연주의적인 스타일을 살려보려면 어떤 디자인을 선택해야 하나요 \n",
      "정답문장 : 수 매치를 쉽게 자연주의적인 방식을 하며 소재는 인한 방법 알려져 것이 낮은 아니라 패턴의 컬러매치를 길게 말합니다 분위기를 복도나 위치를 정도를 질감도 또한 유의해야 \n",
      "번역문장 :  비교적 비교적 비교적 비교적 비교적 비교적 비교적 비교적 비교적 비교적 비교적 비교\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "입력문장 : 브래킷 조명에 대해 설명해줘 \n",
      "정답문장 : 수 선명한 가능성이 배경 고려하며 않을 경우 중립한 작업은 벽등을 단점으로는 기존 인해 할 또는 건물의 단열 해변 활용할 책장을 가능한 있는 직물을 교체에 또는 도움이 있습니다 \n",
      "번역문장 :  비교적 비교적 비교적 비교적 비교적 비교적 비교적 비교적 비교적 비교적 비교적 비교\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [50, 100, 200]:\n",
    "    input_seq = encoder_input_train[seq_index:seq_index+1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "\n",
    "    print(\"입력문장 :\",seq_to_src(encoder_input_train[seq_index]))\n",
    "    print(\"정답문장 :\",seq_to_tar(decoder_input_train[seq_index]))\n",
    "    print(\"번역문장 :\",decoded_sentence[0:-5])\n",
    "    print(\"-\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
